{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerías, variables y funciones auxiliares para la ejecución de las celdas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Índices de los landmarks que definen el contorno de la cara\n",
    "face_outline_indices = [\n",
    "    10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, \n",
    "    378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, \n",
    "    162, 21, 54, 103, 67, 109\n",
    "]\n",
    "\n",
    "left_eye_indices = [\n",
    "    33, 7, 163, 144, 145, 153, 154, 155, 133, 157, 158, 159, 160, 161, 246\n",
    "]\n",
    "\n",
    "right_eye_indices = [\n",
    "    362, 398, 384, 385, 386, 387, 388, 466, 373, 374, 380\n",
    "]\n",
    "\n",
    "upper_mouth_indices = [\n",
    "    61, 185, 40, 39, 37, 0, 267, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181\n",
    "]\n",
    "\n",
    "lower_mouth_indices = [\n",
    "    146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 409, 270, 267, 0, 37, 39, 40, 185\n",
    "]\n",
    "\n",
    "# Función para redimensionar y rotar una imagen\n",
    "def resize_and_rotate(image, width, height, angle_deg):\n",
    "    resized = cv2.resize(image, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    center = (width // 2, height // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle_deg, 1.0)\n",
    "    rotated = cv2.warpAffine(resized, rotation_matrix, (width, height), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "# Función para ajustar dimensiones y recortar la imagen si es necesario\n",
    "def adjust_and_crop(image, x, y, iw, ih):\n",
    "    start_x = max(0, x)\n",
    "    start_y = max(0, y)\n",
    "    x_offset = 0 if x >= 0 else abs(x)\n",
    "    y_offset = 0 if y >= 0 else abs(y)\n",
    "    h_end = min(ih, y + image.shape[0]) - start_y\n",
    "    w_end = min(iw, x + image.shape[1]) - start_x\n",
    "    cropped = image[y_offset:y_offset + h_end, x_offset:x_offset + w_end]\n",
    "    return start_x, start_y, cropped\n",
    "\n",
    "# Función para superponer una imagen con transparencia\n",
    "def overlay_transparent(base_image, overlay, x, y):\n",
    "    h, w = overlay.shape[:2]\n",
    "    for i in range(3):  # Para cada canal (BGR)\n",
    "        base_image[y:y+h, x:x+w, i] = \\\n",
    "            base_image[y:y+h, x:x+w, i] * (1 - overlay[:, :, 3] / 255.0) + \\\n",
    "            overlay[:, :, i] * (overlay[:, :, 3] / 255.0)\n",
    "        \n",
    "# Función para crear un overlay basado en landmarks (ojos o boca)\n",
    "def create_landmark_overlay(image, landmarks, indices_one, indices_two, dilation_size, color):\n",
    "    ih, iw = image.shape[:2]\n",
    "    mask = np.zeros((ih, iw), dtype=np.uint8)\n",
    "    points_one = [(int(landmarks[i].x * iw), int(landmarks[i].y * ih)) for i in indices_one]\n",
    "    points_two = [(int(landmarks[i].x * iw), int(landmarks[i].y * ih)) for i in indices_two]\n",
    "    cv2.polylines(mask, [np.array(points_one)], isClosed=True, color=255, thickness=1)\n",
    "    cv2.polylines(mask, [np.array(points_two)], isClosed=True, color=255, thickness=1)\n",
    "    dilated_mask = cv2.dilate(mask, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dilation_size, dilation_size)))\n",
    "    overlay = np.zeros_like(image)\n",
    "    overlay[dilated_mask == 255] = color\n",
    "    return overlay\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demostración de los puntos clave que serán usados para posicionar el sombrero y el collar, así como el contorno de la cara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "# Inicializar la cámara\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"No se puede acceder a la cámara.\")\n",
    "            break\n",
    "\n",
    "        # Convertir la imagen a RGB para procesarla con MediaPipe\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Procesar la imagen para detectar landmarks faciales\n",
    "        results = face_mesh.process(image_rgb)\n",
    "        \n",
    "        # Convertir la imagen de nuevo a BGR para OpenCV\n",
    "        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Verificar si se detectaron caras\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                # Obtener los puntos específicos que forman el contorno de la cara\n",
    "                ih, iw, _ = image_bgr.shape\n",
    "                \n",
    "                contour_points = [\n",
    "                    (int(face_landmarks.landmark[i].x * iw), int(face_landmarks.landmark[i].y * ih)) \n",
    "                    for i in face_outline_indices\n",
    "                ]\n",
    "\n",
    "                cv2.polylines(image_bgr, [np.array(contour_points)], isClosed=True, color=(255, 255, 255), thickness=2)\n",
    "\n",
    "                for i in face_outline_indices:\n",
    "                    # Poner el número del landmark\n",
    "                    if i == 54 or i == 284:\n",
    "                        x = int(face_landmarks.landmark[i].x * iw)\n",
    "                        y = int(face_landmarks.landmark[i].y * ih)\n",
    "                        cv2.circle(image_bgr, (x, y), 5, (0, 0, 255), -1)\n",
    "\n",
    "                # Dibujar una línea que une los landmarks 54 y 284\n",
    "                ul_x, ul_y = int(face_landmarks.landmark[54].x * iw), int(face_landmarks.landmark[54].y * ih)    # Esquina superior izquierda (upper-left)\n",
    "                ur_x, ur_y = int(face_landmarks.landmark[284].x * iw), int(face_landmarks.landmark[284].y * ih)  # Esquina superior derecha (upper-right)\n",
    "                cv2.line(image_bgr, (ul_x, ul_y), (ur_x, ur_y), (0, 255, 0), 2)\n",
    "                # Dibujar una X en el centro de la línea\n",
    "                cx, cy = (ul_x + ur_x) // 2, (ul_y + ur_y) // 2\n",
    "                cv2.line(image_bgr, (cx - 5, cy - 5), (cx + 5, cy + 5), (0, 255, 0), 2)\n",
    "                cv2.line(image_bgr, (cx + 5, cy - 5), (cx - 5, cy + 5), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        # Mostrar el resultado\n",
    "        cv2.imshow('Face Contour', image_bgr)\n",
    "\n",
    "        # Salir con la tecla 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demostración de la detección del contorno de los ojos y la boca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "# Inicializar la cámara\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"No se puede acceder a la cámara.\")\n",
    "            break\n",
    "\n",
    "        # Convertir la imagen a RGB para procesarla con MediaPipe\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Procesar la imagen para detectar landmarks faciales\n",
    "        results = face_mesh.process(image_rgb)\n",
    "        \n",
    "        # Convertir la imagen de nuevo a BGR para OpenCV\n",
    "        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Verificar si se detectaron caras\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                # Obtener los puntos específicos que forman el contorno de la cara\n",
    "                ih, iw, _ = image_bgr.shape\n",
    "                \n",
    "                contour_points = [\n",
    "                    (int(face_landmarks.landmark[i].x * iw), int(face_landmarks.landmark[i].y * ih)) \n",
    "                    for i in face_outline_indices\n",
    "                ]\n",
    "\n",
    "                cv2.polylines(image_bgr, [np.array(contour_points)], isClosed=True, color=(255, 255, 255), thickness=2)\n",
    "\n",
    "                eye_indices = left_eye_indices + right_eye_indices\n",
    "                for i in eye_indices:\n",
    "                    x = int(face_landmarks.landmark[i].x * iw)\n",
    "                    y = int(face_landmarks.landmark[i].y * ih)\n",
    "                    cv2.circle(image_bgr, (x, y), 2, (0, 0, 255), -1)\n",
    "                \n",
    "                mouth_indices = upper_mouth_indices + lower_mouth_indices\n",
    "                for i in mouth_indices:\n",
    "                    x = int(face_landmarks.landmark[i].x * iw)\n",
    "                    y = int(face_landmarks.landmark[i].y * ih)\n",
    "                    cv2.circle(image_bgr, (x, y), 2, (0, 0, 255), -1)\n",
    "\n",
    "\n",
    "        # Mostrar el resultado\n",
    "        cv2.imshow('Face Contour', image_bgr)\n",
    "\n",
    "        # Salir con la tecla 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicación de filtros para los landmarks y superposición de imágenes respecto a los puntos de interés del borde superior de la cara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar MediaPipe Face Mesh (para obtener los landmarks)\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Cargar la imagen del sombrero y collar (sin cambios)\n",
    "hat = cv2.imread('./images/hat_crop.png', cv2.IMREAD_UNCHANGED)\n",
    "hat_h, hat_w, _ = hat.shape\n",
    "\n",
    "ruff = cv2.imread('./images/ruff_crop.png', cv2.IMREAD_UNCHANGED)\n",
    "ruff_h, ruff_w, _ = ruff.shape\n",
    "\n",
    "# Inicializar la cámara\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Inicializar Face Mesh\n",
    "with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5, max_num_faces=2) as face_mesh:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"No se puede acceder a la cámara.\")\n",
    "            break\n",
    "\n",
    "        # Convertir la imagen a RGB\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Procesar la imagen para obtener los landmarks de la cara\n",
    "        results = face_mesh.process(image_rgb)\n",
    "\n",
    "        # Convertir de nuevo a BGR para OpenCV\n",
    "        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "\n",
    "                # --- CÁLCULO DE MEDIDAS PARA LA POSICIÓN Y ROTACIÓN DE LOS OBJETOS ---\n",
    "                # Dimensiones de la imagen\n",
    "                ih, iw, _ = image_bgr.shape\n",
    "                \n",
    "                # Obtener los puntos del contorno de la cara\n",
    "                contour_points = [\n",
    "                    (int(face_landmarks.landmark[i].x * iw), int(face_landmarks.landmark[i].y * ih)) for i in face_outline_indices\n",
    "                ]\n",
    "\n",
    "                # Calcular tamaño y posición del rectángulo que contiene la cara a partir del contorno\n",
    "                x, y, w, h = cv2.boundingRect(np.array(contour_points))\n",
    "                \n",
    "\n",
    "                # Obtener rotación de la cara a partir de la línea superior de la cara, trazada entre los landmarks 54 y 284\n",
    "                ul_x, ul_y = int(face_landmarks.landmark[54].x * iw), int(face_landmarks.landmark[54].y * ih)    # Esquina superior izquierda (upper-left)\n",
    "                ur_x, ur_y = int(face_landmarks.landmark[284].x * iw), int(face_landmarks.landmark[284].y * ih)  # Esquina superior derecha (upper-right)\n",
    "\n",
    "                # Calcular la diferencia en x e y para obtener el ángulo de rotación de la cara\n",
    "                dx = ur_x - ul_x\n",
    "                dy = ur_y - ul_y\n",
    "\n",
    "                # Calcular el ángulo de rotación, como el ángulo entre la línea y el eje horizontal\n",
    "                angle_deg = -np.degrees(np.arctan2(dy, dx))             # Negativo debido a la inversión de en la imagen de la cámara\n",
    "                \n",
    "                \n",
    "                # --- POSICIONAMIENTO DEL SOMBRERO Y COLLAR EN LA CARA ---\n",
    "                # Tomamos el punto medio de la línea superior de la cara como referencia\n",
    "                center_x = (ul_x + ur_x) // 2\n",
    "                center_y = (ul_y + ur_y) // 2\n",
    "\n",
    "                # Hallamos la longitud de la línea superior de la cara para usarla de referencia para redimensionar objetos\n",
    "                hypotenuse = math.sqrt(dy ** 2 + dx ** 2)\n",
    "\n",
    "\n",
    "                # --- SOMBRERO ---\n",
    "                # Redimensionado\n",
    "                new_hat_w = int(hypotenuse)*2                       # Sombrero 2 veces más ancho que la cara\n",
    "                new_hat_h = int(hat_h * (new_hat_w / hat_w))        # Mantener proporción para el alto\n",
    "\n",
    "                # Rotación del sombrero acorde al ángulo de la cara\n",
    "                rotated_hat = resize_and_rotate(hat, new_hat_w, new_hat_h, angle_deg)\n",
    "                \n",
    "                rotated_hat_h, rotated_hat_w, _ = rotated_hat.shape\n",
    "\n",
    "                # Posición inicial del sombrero en la imagen, centrado con el punto medio de los ojos\n",
    "                x_hat = center_x - (rotated_hat_w // 2)\n",
    "                y_hat = center_y - (rotated_hat_h // 2) - int(0.3 * h)  # Posicionar el sombrero justo encima de la cara con este pequeño desplazamiento\n",
    "\n",
    "                # Ajustar dimensiones y recortar si se sale de los límites de la imagen\n",
    "                x_hat, y_hat, rotated_hat = adjust_and_crop(rotated_hat, x_hat, y_hat, iw, ih)\n",
    "\n",
    "                # Superponer el sombrero con transparencia\n",
    "                overlay_transparent(image_bgr, rotated_hat, x_hat, y_hat)\n",
    "\n",
    "\n",
    "                # --- COLLAR ---\n",
    "                # Redimensionado\n",
    "                new_ruff_w = int(w * 1.8)                            # Collar más ancho que la cara\n",
    "                new_ruff_h = int(ruff_h * (new_ruff_w / ruff_w))     # Mantener proporción\n",
    "                resized_ruff = cv2.resize(ruff, (new_ruff_w, new_ruff_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                # Calcular la posición del collar centrado respecto a la cara\n",
    "                x_ruff = x - int((new_ruff_w - w) / 2)              # Centrar el collar horizontalmente\n",
    "                y_ruff = y + h - int(0.15 * new_ruff_h)             # Posicionar el collar justo debajo de la cara con este pequeño desplazamiento\n",
    "\n",
    "                # Ajustar dimensiones y recortar si se sale de los límites de la imagen\n",
    "                x_ruff, y_ruff, resized_ruff = adjust_and_crop(resized_ruff, x_ruff, y_ruff, iw, ih)\n",
    "\n",
    "                # Superponer el collar con transparencia\n",
    "                overlay_transparent(image_bgr, resized_ruff, x_ruff, y_ruff)\n",
    "                \n",
    "                \n",
    "                # --- DIBUJAR CONTORNOS DE OJOS Y BOCA ---\n",
    "                # Dibujar contorno de los ojos y de la boca\n",
    "                eye_overlay = create_landmark_overlay(image_bgr, face_landmarks.landmark, left_eye_indices, right_eye_indices, 5, (0, 80, 255))\n",
    "                mouth_overlay = create_landmark_overlay(image_bgr, face_landmarks.landmark, upper_mouth_indices, lower_mouth_indices, 10, (0, 0, 255))\n",
    "                combined_overlay = cv2.addWeighted(eye_overlay, 0.5, mouth_overlay, 0.5, 0)\n",
    "                image_bgr = cv2.addWeighted(combined_overlay, 0.4, image_bgr, 1, 0)\n",
    "\n",
    "\n",
    "        # Mostrar la imagen con el filtro aplicado\n",
    "        cv2.imshow('Face Filter', image_bgr)\n",
    "\n",
    "        # Salir si se presiona la tecla 'q'\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Liberar la cámara y cerrar las ventanas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
